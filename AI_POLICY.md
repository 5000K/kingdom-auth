# AI Policy

This document outlines the policies and guidelines for the ethical of AI technologies (especially LLMs) within this project. 
Our commitment is to ensure that AI technologies are used in ways that align with the core values of the project.

Commiting code to this project means you will be following these guidelines. 

## Why this policy?
LLMs can enhance a developers productivity significantly. However, they also introduce risks.  There is a lot of bad code out there. They are trained that code as much as they are trained on the good code.  LLMs can (and will) produce code that looks good but just blatantly isn't. LLMs kinda invite to stop critical thinking. I've seen devs just accept whatever the LLM produces without questioning it. This is dangerous.

> kingdom-auth is a security-focused project. Security is hard. LLMs are (demonstrably) not reliable enough to be trusted here.

**BUT:**

LLMs can be a great tool to enhance productivity, if used correctly. This policy is not about banning LLMs. It's about using them responsibly.

## Understand the output.
You will ALWAYS review **and understand** the code generated by LLMs. You are responsible for this. Do not accept **anything** blindly. Ensure it meets the project's standards and requirements. kingdom-auth is about security. Security is hard. LLMs are never a replacement for knowing what you are doing. Because they don't know what they are doing (by definition - they are not actually thinking beings at the current state of their tech...).

Commiting code to this project means, that you know what you are doing, and you are responsible for your actions. You will not blame AI for mistakes you are ultimately responsible for. You take full ownership of your addition to the project.
